#!/usr/bin/env python3# -*- coding: utf-8 -*-"""Created on Tue Jan 14 12:55:02 2025@author: KalenJosifovski""""""Model definitions package."""import torchimport torch.nn as nnimport torch.nn.functional as Fclass ProteinConv1DClassifier(nn.Module):    def __init__(self, sequence_length, input_dim=26, conv_out_channels=64, kernel_size=5, pool_size=2):        super(ProteinConv1DClassifier, self).__init__()        self.conv1 = nn.Conv1d(in_channels=input_dim, out_channels=conv_out_channels, kernel_size=kernel_size)        self.pool = nn.MaxPool1d(kernel_size=pool_size)        # Compute the reduced sequence length after convolution and pooling        reduced_length = (sequence_length - (kernel_size - 1)) // pool_size        if reduced_length <= 0:            raise ValueError(                f"Reduced length is non-positive: {reduced_length}. Check sequence_length, kernel_size, and pool_size."            )        print(f"Computed reduced length: {reduced_length}")        # Fully connected layers        self.fc1 = nn.Linear(conv_out_channels * reduced_length, 128)        self.fc2 = nn.Linear(128, 1)  # Binary classification    def forward(self, x):        # Conv1D expects input shape: (batch_size, input_dim, seq_len)        # print("Input shape:", x.shape)  # Shape before Conv1D        x = x.permute(0, 2, 1)  # Change to (batch_size, input_dim, seq_len)        # print("Shape after permute for Conv1D:", x.shape)  # (batch_size, input_dim, seq_len)        x = self.pool(F.relu(self.conv1(x)))  # Shape: (batch_size, conv_out_channels, reduced_length)        # print("Shape after Conv1D and pooling:", x.shape)  # Expected: (batch_size, conv_out_channels, reduced_length)        # Ensure the flattened size matches the expected size for fc1        expected_flattened_size = self.fc1.in_features        actual_flattened_size = x.size(1) * x.size(2)        if expected_flattened_size != actual_flattened_size:            raise RuntimeError(                f"Flattened size mismatch: Expected {expected_flattened_size}, got {actual_flattened_size}."            )        # Flatten for fully connected layers        x = x.view(x.size(0), -1)  # Shape: (batch_size, conv_out_channels * reduced_length)        # Fully connected layers        x = F.relu(self.fc1(x))        x = torch.sigmoid(self.fc2(x))  # Binary classification        return x